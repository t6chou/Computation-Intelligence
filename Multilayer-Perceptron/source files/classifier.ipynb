{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "# make it easier to understand by importing the required libraries within keras\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data file IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 14)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"randomized_data.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and normalize traing and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (132, 13)\n",
      "Training labels shape: (132,)\n",
      "Test set shape: (45, 13)\n",
      "Test label shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "# column 1 = label, column 2 -> 14 = input features\n",
    "(x, y) = df.iloc[:, 1:14], df.iloc[:, 0]\n",
    "\n",
    "# normalization\n",
    "n_x = MinMaxScaler().fit_transform(x)\n",
    "\n",
    "# 75% for training, 25% for testing \n",
    "x_train, x_test, y_train, y_test = train_test_split(n_x, y, test_size=0.25)\n",
    "\n",
    "print('Training set shape: {}'.format(x_train.shape))\n",
    "print('Training labels shape: {}'.format(y_train.shape))\n",
    "print('Test set shape: {}'.format(x_test.shape))\n",
    "print('Test label shape: {}'.format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and convert labels to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes are: {1, 2, 3}\n",
      "The values in the input data range from 0.0 to 1.0\n"
     ]
    }
   ],
   "source": [
    "labels = set(y_train)\n",
    "\n",
    "if len(y_train.shape) == 1:\n",
    "    y_train = keras.utils.to_categorical(y_train-1, num_classes=3)\n",
    "    y_test = keras.utils.to_categorical(y_test-1, num_classes=3)\n",
    "    \n",
    "print('The classes are: {}'.format(labels))\n",
    "print('The values in the input data range from {} to {}'.format(x_train.min(),x_train.max()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for training and testing model, here I used categorical crossentropy as loss function since there are more than 2 label classes. Epoch is set to 100 to prevent underfitting. Finally, I used the test accuracy as metric for the model. Since the classification is simple enough, cross validation is not implemented here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    h = model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "    # return test accurancy \n",
    "    return model.evaluate(x_test,y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for generating a 4x4 grid of accuracy values comparing different combination of neurons and hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGrid(data):\n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame(data, columns=[\"4\", \"16\", \"32\", \"64\"],\n",
    "                    index=[\"1\", \"2\", \"3\", \"4\"])\n",
    "\n",
    "    # print the dataframe\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model. Here I tested 16 different combinations of number of nodes and number of layers to find the best possible accuracy performance and used sigmoid as  activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          4        16        32        64\n",
      "1  0.977778  0.955556  0.933333  0.600000\n",
      "2  0.977778  0.955556  0.977778  0.977778\n",
      "3  0.977778  0.955556  0.977778  0.977778\n",
      "4  0.977778  0.977778  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "n_neurons = [4, 16, 32, 64]\n",
    "n_layers = [1, 2, 3, 4]\n",
    "\n",
    "M = np.empty((len(n_neurons), len(n_layers)), dtype=object)\n",
    "accuracy = np.empty((len(n_neurons), len(n_layers)), dtype=float)\n",
    "\n",
    "for i in range(len(n_neurons)):\n",
    "    for j in range(len(n_layers)):\n",
    "        # model initialization\n",
    "        M[i][j] = keras.models.Sequential()\n",
    "        # input layer + 1st hidden layer \n",
    "        M[i][j].add(Dense(n_neurons[i], activation='sigmoid', input_shape=(13,)))\n",
    "        # hidden layers\n",
    "        for layer in range(n_layers[j]-1):\n",
    "            M[i][j].add(Dense(n_neurons[i], activation='sigmoid'))\n",
    "        # output layer \n",
    "        M[i][j].add(Dense(3, activation='softmax'))\n",
    "        # train\n",
    "        accuracy[i,j] = fit(M[i, j], x_train, y_train, x_test, y_test)\n",
    "\n",
    "generateGrid(accuracy)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the table, the best possible classification performance for accuracy is 100% for both 32 neurons X 4 layers and 64 neurons X 4 layers, since both models are complex enough to ensure that the model is not underfitted. Interestingly the model is not overfitted as well, this could be because the model is still sufficiently simple due to the small layer count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I used the model with 64 neurons X 4 layers to predict the classification of the 3 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[13.72, 1.43, 2.5, 16.7, 108, 3.4, 3.67, 0.19, 2.04, 6.8, 0.89, 2.87, 1285],\n",
    "                   [12.04, 4.3, 2.38, 22, 80, 2.1, 1.75, 0.42, 1.35, 2.6, 0.79, 2.57, 580],\n",
    "                   [14.13, 4.1, 2.74, 24.5, 96, 2.05, 0.76, 0.56, 1.35, 9.2, 0.61, 1.6, 560]])\n",
    "\n",
    "n_test = MinMaxScaler().fit_transform(test)\n",
    "\n",
    "prediction = M[3,3].predict(n_test)\n",
    "\n",
    "print(list(map(lambda x: list(map(int, map(round, x))), prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification result of the 3 products are: [0,1,2] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f0f153560ccfe3a7f8a3a797eff40f75c915e6b8a0d65e3e90b6570fc21b6e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
